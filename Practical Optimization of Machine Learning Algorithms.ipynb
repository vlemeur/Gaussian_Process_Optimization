{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f8f3c5f0-2ccf-4a0a-9075-e9bfcf181abe"
    }
   },
   "source": [
    "#  <center>Practical Bayesian Optimization of Machine Learning Algorithm </center>\n",
    "<b> Vincent LE MEUR, Thomas Levy,Timothée Watrigant </b>\n",
    "### <center><b></b></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'article étudié est le suivant : https://papers.nips.cc/paper/4522-practical-bayesian-optimization-of-machine-learning-algorithms.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0183677a-1b50-42e0-a809-e8547e26f1f6"
    }
   },
   "source": [
    "Pour installer un kernel python 2 sur jupyter\n",
    "http://ipython.readthedocs.io/en/stable/install/kernel_install.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le code de l'implémentation est : \n",
    "https://github.com/JasperSnoek/spearmint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e06242bb-1872-4821-bc98-3e1c6a73a315"
    }
   },
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8addeda1-54b2-4f13-a3a5-e9f10bfd0d5e"
    }
   },
   "source": [
    "Le choix des hyper-paramètres (ex : taux d'apprentissage, nombre de couches d'un réseau de neuronnes...) d'un modèle de Machine Learning peut être fastidieux et relève plus\n",
    "souvent de l’expérience empirique que d'une méthode exacte. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cette optimisation peut être vue comme celle d'une fonction inconnue $f(x)$ qui évalue l'efficacité d'un algorithme avec des hyperparamètres $x$ fixés."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'article propose un algorithme basé\n",
    "sur l'optimisation bayésienne avec un prior Processus Gaussien (GP) pour automatiser le choix des\n",
    "hyper-paramètres. Cet algorithme a été appliqué et validé sur 3 problèmes de Machine Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "69ecaa85-62d2-4f1e-9224-1b5069faa2ec"
    }
   },
   "source": [
    "Nous allons décrire le principe de l'optimization Bayésienne, puis l'algorithme utilisé par les auteurs de l'étude. Enfin, nous essaierons de l'appliquer à un nouveau problème de\n",
    "machine learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "202b58ed-277a-45e6-9c72-e82fcf59ef44"
    }
   },
   "source": [
    "# 1) L'optimisation Bayésienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d2bd66e3-c9cf-4872-b95d-2a47af18908e"
    }
   },
   "source": [
    "L'idée est de considérer que la fonction inconnue $f(x)$ est issue d'un Prior et dont la distribution a posteriori reste cohérente avec ce Prior au fur et à mesure des observations. L'objectif est de trouver le minimum de cette fonction $f : \\mathcal{X} \\rightarrow \\mathcal{R}$ où $\\mathcal{X}$ désigne l'ensemble dans lequel évolue les hyperparamètres."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "9f7652f1-54ea-477e-8f93-8663de1b147d"
    }
   },
   "source": [
    "Dans notre cas précis, une observation correspond à faire tourner un algorithme de Machine Learning avec un ensemble d'hyperparamètres fixés et d'en évaluer l'efficacité."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "b8b427ba-9590-4f59-96db-00893f168351"
    }
   },
   "source": [
    "L'optimisation bayésienne permet de choisir de manière \"optimale\" le prochain set d'hyperparamètres à tester. En effet, cette approche intégre l'incertitude sur la fonction $f$ de façon à la réduire lors de la prochaine évaluation. Ainsi comme dans beaucoup d'approches bayésiennes, l'ensemble de l'information des données est utilisée."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6073ae97-1ee2-4893-8fc5-fc39f1dbeaa0"
    }
   },
   "source": [
    "Pour pratiquer de l'optimisation bayésienne, il y a deux choix principaux à réaliser.\n",
    "La premier choix est celui du <b>Prior</b> concernant la fonction $f$.\n",
    "Le second choix est celui de la <b>fonction d'acquisition</b>. Cette dernière va servir à évaluer le prochain point à tester."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6a2fd651-b6c6-46bd-b480-841a68450e03"
    }
   },
   "source": [
    "Les auteurs de l'article ont choisi comme prior un <b>Processus Gaussien</b> qui offre une excellente flexibilité sur la fonction $f$. Ainsi par définition, nos observations obtenues seront de la forme : $ \\{ x_n,y_n\\}$ avec $y_n \\sim \\mathcal{N}(f(x_n),\\nu)$ avec $\\nu$ la variance du bruit de mesure des observations.\n",
    "Le support d'un tel processus peut se résumer avec deux fonctions : \n",
    "$m : \\mathcal{X} \\rightarrow \\mathcal{R}$ la fonction moyenne, et $K : \\mathcal{X} \\times \\mathcal{X} \\rightarrow \\mathcal{R} $ la fonction de covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "42523012-b509-4a8e-bb26-bb0a6ec93de9"
    }
   },
   "source": [
    "La fonction d'acquisition quand à elle désigne une fonction $a : \\mathcal{X} \\rightarrow \\mathcal{R}^+ $ qui nous permet de choisir le prochain point d'évaluation : $x_{next} = argmax_{\\mathcal{X}}a(x)$. Ces fonctions dépendent des paramètres du Processus Gaussien ainsi que des précédentes observations. Plusieurs fonctions sont alors possibles comme \"Probability of Improvment\" qui maximise la probabilité d'avoir une \"meilleure observation\" par rapport à toutes les observations précédentes ou encore le \"GP Upper Confidence Bound\". Le choix des auteurs de l'article s'est porté sur l' <b>Expected Improvment $a_{EI}$</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "99b2c287-fe78-48ed-b794-235d7f79b3da"
    }
   },
   "source": [
    "Soit $\\theta$ les hyperparamètres de notre GP, $\\mu$ la fonction moyenne de prédiction et $\\sigma$ la fonction de variance sous le prior GP (à ne pas confondre avec les fonctions $m$ et $K$ précédentes),$x_{best}=argmin_{x_1,..,x_n}f(x)$ la meilleure observation actuelle, $\\gamma(x) = \\dfrac{f(x_{best})-\\mu(x; \\{x_n,y_n\\},\\theta)}{\\sigma(x;\\{x_n,y_n\\},\\theta)}$ et $\\Phi$ la fonction de répartition de la loi Normale alors l'Expected Improvment est définie par : \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "69f12172-b8fa-41ef-a61d-0e1df5579e24"
    }
   },
   "source": [
    "$a_{EI}(x; \\{x_n,y_n\\},\\theta) = \\sigma(x; \\{x_n,y_n\\},\\theta)(\\gamma(x)\\Phi(x) + \\mathcal{N}(\\gamma(x);1))$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce choix est justifié par de bonnes performances en minimisation et l'absence d'hyperparamètres supplémentaires."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2) Points clés de l'étude"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le travail réalisé dans ce contexte s'attaque à trois difficultés précises. La première est celle du choix de la fonction de covariance $K$ du GP qui peut être déterminant d'un problème à l'autre. La seconde est la volonté de prendre en compte le temps d'évaluation de la fonction $f$ qui peut changer radicalement d'un problème à l'autre. En effet, on rappelle que l'évaluation de cette fonction implique la mise en place d'un algorithme de Machine Learning complet. Enfin, malgré la nature séquentielle de cette optimisation bayésienne, les auteurs ont cherché à tirer profit de la parallélisation des calculs propres aux environnements distribués."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  a) Le choix de la fonction de covariance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le choix de cette fonction covariance peut induire d'importantes hypothèses sur la fonction $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un choix courant est celui du \"squared exponential kernel\" (ou ARD). Néanmoins, les fonctions obtenues pour ce choix ont une régularité importante. Bien que cela soit positif d'un point de vue de l'optimisation, cela reste très peu réaliste pour l'optimisation complexe de notre fonction $f$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est pourquoi les auteurs ont plutôt choisi comme fonction de covariance un choix plus \"exotique\", l'ARD Matérn 5/2 kernel :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ K_{M52}(x,x') = \\theta_0(1+ \\sqrt{5r^2(x,x')} + \\frac{5}{3}r^2(x,x'))e^{-\\sqrt{5r^2(x,x')}} $\n",
    "avec $ r^2(x,x')=\\sum_{d=1}^D(x_d - x_d')^2/\\theta^2_d$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On constate alors la présence de D+3 hyperparamètres issue de notre processus Gaussien (D est la dimension des vecteurs $x \\in \\mathcal{X}$) :\n",
    "- D paramètres de longeurs d'échelles $\\theta_{1:D}$\n",
    "- $\\theta_0$ l'amplitude de la covariance \n",
    "- $\\nu$ le bruit de mesure et $m$ la moyenne\n",
    "\n",
    "On concatène alors tous ces paramètres en un unique vecteur $\\theta$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il y a donc D+3 hyperparamètres à sélectionner. Pour avoir un traitement bayésien complet, l'idée des auteurs a été de modifier la fonction d'acquisition $a$ précédente en intégrant selon ce vecteur $\\theta$. On obtient alors la fonction d'acquisition intégrée suivante : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$â(x;\\{x_n,y_n\\}) = \\int a(x:\\{x_n,y_n\\},\\theta)p(\\theta | \\{x_n,y_n\\}_{n=1}^N)d\\theta $ \n",
    "\n",
    "avec $p(\\theta | \\{x_n,y_n\\}_{n=1}^N)$ la distribution marginale issue des données et du processus Gaussien."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il s'agit d'une généralisation permettant de prendre en compte l'incertitude sur le choix des hyperparamètres du GP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## b) La prise en compte du temps d'évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bien que l'optimisation bayésienne précédente nous permette d'effectuer un choix optimal pour la prochaîne évaluation de f, cela peut se solder en pratique par un temps d'exécution très long (cela dépend fortement de la nature de l'espace des hyperparamètres $\\mathcal{X}$). Cela rendrait donc l'étude non applicable en pratique avec des configurations machines classiques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction $f$ nous est inconnue tout comme la fonction $c : \\mathcal{X} \\rightarrow \\mathcal{R}^+$ qui évalue le temps d'évaluation de la fonction $f$ au point $x$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le point clé ici est d'utiliser toute la machinerie de notre optimisation bayésienne pour évaluer $ln$ $c(x)$ en plus de $f(x)$ en supposant que ces deux fonctions sont indépendantes l'une de l'autre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ainsi il est possible de tracer l'\"expected improvment per second\" en divisant par cette évaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'algorithme nous permet non seulement de choisir des points qui donneront une bonne optimisation de f mais également des points pour lesquels cette évaluation n'est pas trop couteuse en temps d'exécution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## c) La parallélisation de l'optimisation Bayésienne par des acquisitions de Monte Carlo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bon cette partie je l'ai toujours pas comprise faut que je creuse "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3) Implémentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T16:12:05.869469Z",
     "start_time": "2018-01-02T16:12:05.861993Z"
    }
   },
   "outputs": [],
   "source": [
    "# Si il y a des problèmes pour importer numpy et scipy sur ce kernel les deux commandes ci-dessous devraient régler le problème\n",
    "#import sys\n",
    "#!conda install --yes --prefix {sys.prefix} numpy\n",
    "#!{sys.executable} -m pip install scipy\n",
    "#!{sys.executable} -m pip install weave"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-02T15:48:53.112280Z",
     "start_time": "2018-01-02T15:48:52.926974Z"
    }
   },
   "source": [
    "### Fonctions utilisées pour le GP (contenues dans gp.py) : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-01-10T09:30:44.586968Z",
     "start_time": "2018-01-10T09:30:43.972003Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.linalg as spla\n",
    "import scipy.optimize as spo\n",
    "import scipy.io as sio\n",
    "import weave\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except:\n",
    "    pass\n",
    "\n",
    "SQRT_3 = np.sqrt(3.0)\n",
    "SQRT_5 = np.sqrt(5.0)\n",
    "\n",
    "def dist2(ls, x1, x2=None):\n",
    "     # Assumes NxD and MxD matrices.\n",
    "     # Compute the squared distance matrix, given length scales.\n",
    "     \n",
    "    if x2 is None:\n",
    "        \n",
    "         # Find distance with self for x1.\n",
    " \n",
    "         # Rescale.\n",
    "        xx1 = x1 / ls        \n",
    "        xx2 = xx1\n",
    " \n",
    "    else:\n",
    "        \n",
    "        \n",
    "         # Rescale.\n",
    "        xx1 = x1 / ls\n",
    "        xx2 = x2 / ls\n",
    "     \n",
    "    r2 = np.maximum(-(np.dot(xx1, 2*xx2.T) \n",
    "                        - np.sum(xx1*xx1, axis=1)[:,np.newaxis]\n",
    "                        - np.sum(xx2*xx2, axis=1)[:,np.newaxis].T), 0.0)\n",
    " \n",
    "    return r2\n",
    "\n",
    "\n",
    "def grad_dist2(ls, x1, x2=None):\n",
    "    if x2 is None:\n",
    "        x2 = x1\n",
    "    # Rescale.\n",
    "    x1 = x1 / ls\n",
    "    x2 = x2 / ls\n",
    "     \n",
    "    N = x1.shape[0]\n",
    "    M = x2.shape[0]\n",
    "    D = x1.shape[1]\n",
    "    gX = np.zeros((x1.shape[0],x2.shape[0],x1.shape[1]))\n",
    " \n",
    "    code = \\\n",
    "    \"\"\"\n",
    "    for (int i=0; i<N; i++)\n",
    "        for (int j=0; j<M; j++)\n",
    "            for (int d=0; d<D; d++)\n",
    "               gX(i,j,d) = (2/ls(d))*(x1(i,d) - x2(j,d));\n",
    "     \"\"\"\n",
    "    try:\n",
    "        scipy.weave.inline(code, ['x1','x2','gX','ls','M','N','D'], \\\n",
    "                        type_converters=scipy.weave.converters.blitz, \\\n",
    "                        compiler='gcc')\n",
    "    except:\n",
    "        # The C code weave above is 10x faster than this:\n",
    "        for i in xrange(0,x1.shape[0]):\n",
    "            gX[i,:,:] = 2*(x1[i,:] - x2[:,:])*(1/ls)\n",
    " \n",
    "    return gX\n",
    "\n",
    "def SE(ls, x1, x2=None, grad=False):\n",
    "    ls = np.ones(ls.shape)\n",
    "    cov = np.exp(-0.5 * dist2(ls, x1, x2))\n",
    "    if grad:\n",
    "        return (cov, grad_ARDSE(ls, x1, x2))\n",
    "    else:\n",
    "        return cov    \n",
    "    \n",
    "def ARDSE(ls, x1, x2=None, grad=False):\n",
    "    cov = np.exp(-0.5 * dist2(ls, x1, x2))\n",
    "    if grad:\n",
    "        return (cov, grad_ARDSE(ls, x1, x2))\n",
    "    else:\n",
    "        return cov\n",
    "\n",
    "def grad_ARDSE(ls, x1, x2=None):\n",
    "    r2 = dist2(ls, x1, x2)\n",
    "    r  = np.sqrt(r2)\n",
    "    return -0.5*np.exp(-0.5*r2)[:,:,np.newaxis] * grad_dist2(ls, x1, x2)\n",
    "\n",
    "def Matern32(ls, x1, x2=None, grad=False):\n",
    "    r   = np.sqrt(dist2(ls, x1, x2))\n",
    "    cov = (1 + SQRT_3*r) * np.exp(-SQRT_3*r)\n",
    "    if grad:\n",
    "        return (cov, grad_Matern32(ls, x1, x2))\n",
    "    else:\n",
    "        return cov\n",
    "\n",
    "\n",
    "def grad_Matern32(ls, x1, x2=None):\n",
    "    r       = np.sqrt(dist2(ls, x1, x2))\n",
    "    grad_r2 = -1.5*np.exp(-SQRT_3*r)\n",
    "    return grad_r2[:,:,np.newaxis] * grad_dist2(ls, x1, x2)\n",
    " \n",
    "def Matern52(ls, x1, x2=None, grad=False):\n",
    "    r2  = np.abs(dist2(ls, x1, x2))\n",
    "    r   = np.sqrt(r2)\n",
    "    cov = (1.0 + SQRT_5*r + (5.0/3.0)*r2) * np.exp(-SQRT_5*r)\n",
    "    if grad:\n",
    "        return (cov, grad_Matern52(ls, x1, x2))\n",
    "    else:\n",
    "        return cov\n",
    "\n",
    "\n",
    "def Matern52(ls, x1, x2=None, grad=False):\n",
    "    r2  = np.abs(dist2(ls, x1, x2))\n",
    "    r   = np.sqrt(r2)\n",
    "    cov = (1.0 + SQRT_5*r + (5.0/3.0)*r2) * np.exp(-SQRT_5*r)\n",
    "    if grad:\n",
    "        return (cov, grad_Matern52(ls, x1, x2))\n",
    "    else:\n",
    "        return cov\n",
    "\n",
    "def grad_Matern52(ls, x1, x2=None):\n",
    "    r       = np.sqrt(dist2(ls, x1, x2))\n",
    "    grad_r2 = -(5.0/6.0)*np.exp(-SQRT_5*r)*(1 + SQRT_5*r)\n",
    "    return grad_r2[:,:,np.newaxis] * grad_dist2(ls, x1, x2)\n",
    "\n",
    "\n",
    "class GP:\n",
    "    def __init__(self, covar=\"Matern52\", mcmc_iters=10, noiseless=False):\n",
    "        self.cov_func        = globals()[covar]\n",
    "        self.mcmc_iters      = int(mcmc_iters)\n",
    "        self.D               = -1\n",
    "        self.hyper_iters     = 1\n",
    "        self.noiseless       = bool(int(noiseless))\n",
    "        self.hyper_samples = []\n",
    "        \n",
    "        self.noise_scale = 0.1  # horseshoe prior \n",
    "        self.amp2_scale  = 1    # zero-mean log normal prior\n",
    "        self.max_ls      = 2    # top-hat prior on length scales \n",
    "\n",
    "    def real_init(self, dims, values):\n",
    "        # Input dimensionality. \n",
    "        self.D = dims\n",
    "\n",
    "        # Initial length scales.               \n",
    "        self.ls = np.ones(self.D)\n",
    "\n",
    "        # Initial amplitude.        \n",
    "        self.amp2 = np.std(values)\n",
    "\n",
    "        # Initial observation noise.                                          \n",
    "        self.noise = 1e-3\n",
    "\n",
    "        # Initial mean.\n",
    "        self.mean = np.mean(values)\n",
    "\n",
    "    def cov(self, x1, x2=None):\n",
    "        if x2 is None:\n",
    "            return self.amp2 * (self.cov_func(self.ls, x1, None)\n",
    "                                + 1e-6*np.eye(x1.shape[0]))\n",
    "        else:\n",
    "            return self.amp2 * self.cov_func(self.ls, x1, x2)\n",
    "\n",
    "    def logprob(self, comp, vals):\n",
    "            mean  = self.mean\n",
    "            amp2  = self.amp2\n",
    "            noise = self.noise\n",
    "            \n",
    "            cov   = amp2 * (self.cov_func(self.ls, comp, None) + 1e-6*np.eye(comp.shape[0])) + noise*np.eye(comp.shape[0])\n",
    "            chol  = spla.cholesky(cov, lower=True)\n",
    "            solve = spla.cho_solve((chol, True), vals - mean)\n",
    "            lp    = -np.sum(np.log(np.diag(chol)))-0.5*np.dot(vals-mean, solve)\n",
    "            return lp\n",
    "\n",
    "    def optimize_hypers(self, comp, vals):\n",
    "        self.mean = np.mean(vals)\n",
    "        diffs     = vals - self.mean\n",
    "\n",
    "        state = { }\n",
    "\n",
    "        def jitter_chol(covmat):\n",
    "            passed = False\n",
    "            jitter = 1e-8\n",
    "            val = 0\n",
    "            while not passed:\n",
    "                if (jitter > 100000):\n",
    "                    val = spla.cholesky(np.eye(covmat.shape[0]))\n",
    "                    break\n",
    "                try:\n",
    "                    val = spla.cholesky(covmat +\n",
    "                        jitter*np.eye(covmat.shape[0]), lower=True)\n",
    "                    passed = True\n",
    "                except ValueError:\n",
    "                    jitter = jitter*1.1\n",
    "                    print \"Covariance matrix not PSD, adding jitter:\", jitter\n",
    "                    passed = False\n",
    "            return val\n",
    "        \n",
    "        def memoize(amp2, noise, ls):\n",
    "            if ( 'corr' not in state\n",
    "                 or state['amp2'] != amp2\n",
    "                 or state['noise'] != noise\n",
    "                 or np.any(state['ls'] != ls)):\n",
    "\n",
    "                # Get the correlation matrix\n",
    "                (corr, grad_corr) = self.cov_func(ls, comp, None, grad=True)\n",
    "        \n",
    "                # Scale and add noise & jitter.\n",
    "                covmat = (amp2 * (corr + 1e-6*np.eye(comp.shape[0])) \n",
    "                          + noise * np.eye(comp.shape[0]))\n",
    "\n",
    "                # Memoize\n",
    "                state['corr']      = corr\n",
    "                state['grad_corr'] = grad_corr\n",
    "                state['chol']      = jitter_chol(covmat)\n",
    "                state['amp2']      = amp2\n",
    "                state['noise']     = noise\n",
    "                state['ls']        = ls\n",
    "                \n",
    "            return (state['chol'], state['corr'], state['grad_corr'])\n",
    "\n",
    "        def nlogprob(hypers):\n",
    "            amp2  = np.exp(hypers[0])\n",
    "            noise = np.exp(hypers[1])\n",
    "            ls    = np.exp(hypers[2:])\n",
    "\n",
    "            chol  = memoize(amp2, noise, ls)[0]\n",
    "            solve = spla.cho_solve((chol, True), diffs)\n",
    "            lp    = -np.sum(np.log(np.diag(chol)))-0.5*np.dot(diffs, solve)\n",
    "            return -lp\n",
    "        def grad_nlogprob(hypers):\n",
    "            amp2  = np.exp(hypers[0])\n",
    "            noise = np.exp(hypers[1])\n",
    "            ls    = np.exp(hypers[2:])\n",
    "\n",
    "            chol, corr, grad_corr = memoize(amp2, noise, ls)\n",
    "            solve   = spla.cho_solve((chol, True), diffs)\n",
    "            inv_cov = spla.cho_solve((chol, True), np.eye(chol.shape[0]))\n",
    "\n",
    "            jacobian = np.outer(solve, solve) - inv_cov\n",
    "\n",
    "            grad = np.zeros(self.D + 2)\n",
    "\n",
    "            # Log amplitude gradient.\n",
    "            grad[0] = 0.5 * np.trace(np.dot( jacobian, corr + 1e-6*np.eye(chol.shape[0]))) * amp2\n",
    "\n",
    "            # Log noise gradient.\n",
    "            grad[1] = 0.5 * np.trace(np.dot( jacobian, np.eye(chol.shape[0]))) * noise\n",
    "\n",
    "            # Log length scale gradients.\n",
    "            for dd in xrange(self.D):\n",
    "                grad[dd+2] = 1 * np.trace(np.dot( jacobian, -amp2*grad_corr[:,:,dd]*comp[:,dd][:,np.newaxis]/(np.exp(ls[dd]))))*np.exp(ls[dd])\n",
    "\n",
    "            # Roll in the prior variance.\n",
    "            #grad -= 2*hypers/self.hyper_prior\n",
    "\n",
    "            return -grad\n",
    "        \n",
    "        # Initial length scales.\n",
    "        self.ls = np.ones(self.D)\n",
    "        # Initial amplitude.\n",
    "        self.amp2 = np.std(vals)\n",
    "        # Initial observation noise.\n",
    "        self.noise = 1e-3\n",
    "        \n",
    "        hypers     = np.zeros(self.ls.shape[0]+2)\n",
    "        hypers[0]  = np.log(self.amp2)\n",
    "        hypers[1]  = np.log(self.noise)\n",
    "        hypers[2:] = np.log(self.ls)\n",
    "        \n",
    "        # Use a bounded bfgs just to prevent the length-scales and noise from \n",
    "        # getting into regions that are numerically unstable\n",
    "        b = [(-10,10),(-10,10)]\n",
    "        for i in xrange(comp.shape[1]):\n",
    "            b.append((-10,5))\n",
    "  \n",
    "        hypers = spo.fmin_l_bfgs_b(nlogprob, hypers, grad_nlogprob, args=(), bounds=b, disp=0)\n",
    "                \n",
    "        #hypers = spo.fmin_bfgs(nlogprob, hypers, grad_nlogprob, maxiter=100)\n",
    "        hypers = hypers[0]\n",
    "        #hypers = spo.fmin_bfgs(nlogprob, hypers, grad_nlogprob, maxiter=100)\n",
    "\n",
    "        self.amp2  = np.exp(hypers[0])\n",
    "        self.noise = np.exp(hypers[1])\n",
    "        self.ls    = np.exp(hypers[2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  },
  "nbpresent": {
   "slides": {
    "0a534e6a-423b-4796-b8e7-4f0dac1eb099": {
     "id": "0a534e6a-423b-4796-b8e7-4f0dac1eb099",
     "prev": "729bf0d3-8925-4d98-af57-1be56368806d",
     "regions": {
      "f4a3b327-c84f-4a28-b931-857fac58b6d8": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "e06242bb-1872-4821-bc98-3e1c6a73a315",
        "part": "whole"
       },
       "id": "f4a3b327-c84f-4a28-b931-857fac58b6d8"
      }
     }
    },
    "2aab03aa-677e-4a01-afbd-5bcc5c2dd00a": {
     "id": "2aab03aa-677e-4a01-afbd-5bcc5c2dd00a",
     "prev": "ebfcf0b9-7a2c-45b8-9e6d-5c8c6ad77f57",
     "regions": {
      "6d38fcee-008b-42ff-8dba-a6c0c55a19a6": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "42523012-b509-4a8e-bb26-bb0a6ec93de9",
        "part": "whole"
       },
       "id": "6d38fcee-008b-42ff-8dba-a6c0c55a19a6"
      }
     }
    },
    "6178751c-560a-4f4c-a921-ee39bd2e6546": {
     "id": "6178751c-560a-4f4c-a921-ee39bd2e6546",
     "prev": "9886d7e7-2c39-4674-83a4-1cf819d46b4b",
     "regions": {
      "e2c39667-64a7-44b4-9626-e04280cb4f5b": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "d2bd66e3-c9cf-4872-b95d-2a47af18908e",
        "part": "whole"
       },
       "id": "e2c39667-64a7-44b4-9626-e04280cb4f5b"
      }
     }
    },
    "65446d22-252a-49d9-8581-31b8d54140b2": {
     "id": "65446d22-252a-49d9-8581-31b8d54140b2",
     "prev": "f177f24a-0974-485c-a5f7-767a9b2920ef",
     "regions": {
      "fae4c67b-be68-45bd-ac8a-0494a5571450": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "69f12172-b8fa-41ef-a61d-0e1df5579e24",
        "part": "whole"
       },
       "id": "fae4c67b-be68-45bd-ac8a-0494a5571450"
      }
     }
    },
    "6ea40efc-502f-48d4-b3a0-7531069fb5e5": {
     "id": "6ea40efc-502f-48d4-b3a0-7531069fb5e5",
     "prev": "8c17c9db-0b19-4255-8151-a0a15412d5b2",
     "regions": {
      "f49017a8-7066-4721-8fdf-18bd2a163f81": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6073ae97-1ee2-4893-8fc5-fc39f1dbeaa0",
        "part": "whole"
       },
       "id": "f49017a8-7066-4721-8fdf-18bd2a163f81"
      }
     }
    },
    "728d6cbe-fdd7-40ee-87bf-3a7ee7193f01": {
     "id": "728d6cbe-fdd7-40ee-87bf-3a7ee7193f01",
     "prev": "6178751c-560a-4f4c-a921-ee39bd2e6546",
     "regions": {
      "6fcd3065-ae0b-4fb7-85e0-37e9d2bf2cab": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "9f7652f1-54ea-477e-8f93-8663de1b147d",
        "part": "whole"
       },
       "id": "6fcd3065-ae0b-4fb7-85e0-37e9d2bf2cab"
      }
     }
    },
    "729bf0d3-8925-4d98-af57-1be56368806d": {
     "id": "729bf0d3-8925-4d98-af57-1be56368806d",
     "prev": "7698d92d-65eb-41fb-a335-2474de87a720",
     "regions": {
      "7f7a0f8a-3dc6-4508-9ca7-8d9c07387a28": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0183677a-1b50-42e0-a809-e8547e26f1f6",
        "part": "whole"
       },
       "id": "7f7a0f8a-3dc6-4508-9ca7-8d9c07387a28"
      }
     }
    },
    "7698d92d-65eb-41fb-a335-2474de87a720": {
     "id": "7698d92d-65eb-41fb-a335-2474de87a720",
     "prev": null,
     "regions": {
      "e5887c20-7fd3-4346-abb2-db696b90b591": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "f8f3c5f0-2ccf-4a0a-9075-e9bfcf181abe",
        "part": "whole"
       },
       "id": "e5887c20-7fd3-4346-abb2-db696b90b591"
      }
     }
    },
    "7a6ef345-7756-4fc9-93ff-03c3ae7a4dbf": {
     "id": "7a6ef345-7756-4fc9-93ff-03c3ae7a4dbf",
     "prev": "863af350-bac4-4282-a62e-731e4a2a3e65",
     "regions": {
      "edb9121b-a9ea-4e99-be50-605fcb76f615": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "69ecaa85-62d2-4f1e-9224-1b5069faa2ec",
        "part": "whole"
       },
       "id": "edb9121b-a9ea-4e99-be50-605fcb76f615"
      }
     }
    },
    "863af350-bac4-4282-a62e-731e4a2a3e65": {
     "id": "863af350-bac4-4282-a62e-731e4a2a3e65",
     "prev": "0a534e6a-423b-4796-b8e7-4f0dac1eb099",
     "regions": {
      "1cd4b9fc-514e-446c-804c-5373542eb3e5": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "8addeda1-54b2-4f13-a3a5-e9f10bfd0d5e",
        "part": "whole"
       },
       "id": "1cd4b9fc-514e-446c-804c-5373542eb3e5"
      }
     }
    },
    "8c17c9db-0b19-4255-8151-a0a15412d5b2": {
     "id": "8c17c9db-0b19-4255-8151-a0a15412d5b2",
     "prev": "728d6cbe-fdd7-40ee-87bf-3a7ee7193f01",
     "regions": {
      "a26a7087-90e5-43cc-93c3-0ebb0605c074": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "b8b427ba-9590-4f59-96db-00893f168351",
        "part": "whole"
       },
       "id": "a26a7087-90e5-43cc-93c3-0ebb0605c074"
      }
     }
    },
    "9886d7e7-2c39-4674-83a4-1cf819d46b4b": {
     "id": "9886d7e7-2c39-4674-83a4-1cf819d46b4b",
     "prev": "7a6ef345-7756-4fc9-93ff-03c3ae7a4dbf",
     "regions": {
      "d2f54f15-de50-4589-8d6f-afffcc00d673": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "202b58ed-277a-45e6-9c72-e82fcf59ef44",
        "part": "whole"
       },
       "id": "d2f54f15-de50-4589-8d6f-afffcc00d673"
      }
     }
    },
    "ebfcf0b9-7a2c-45b8-9e6d-5c8c6ad77f57": {
     "id": "ebfcf0b9-7a2c-45b8-9e6d-5c8c6ad77f57",
     "prev": "6ea40efc-502f-48d4-b3a0-7531069fb5e5",
     "regions": {
      "e1047a7b-68af-4cac-b81b-04d9427d5f65": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "6a2fd651-b6c6-46bd-b480-841a68450e03",
        "part": "whole"
       },
       "id": "e1047a7b-68af-4cac-b81b-04d9427d5f65"
      }
     }
    },
    "f177f24a-0974-485c-a5f7-767a9b2920ef": {
     "id": "f177f24a-0974-485c-a5f7-767a9b2920ef",
     "prev": "2aab03aa-677e-4a01-afbd-5bcc5c2dd00a",
     "regions": {
      "df224ccd-92fe-4ecd-a30a-dc511586adda": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "99b2c287-fe78-48ed-b794-235d7f79b3da",
        "part": "whole"
       },
       "id": "df224ccd-92fe-4ecd-a30a-dc511586adda"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
